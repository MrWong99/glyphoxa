# Glyphoxa â€” Docker Compose configuration (local stack)
# Use with: docker compose --profile local up
# No cloud API keys required.
#
# Whisper.cpp runs natively inside Glyphoxa (no separate container).

server:
  listen_addr: ":8080"
  log_level: info

providers:
  llm:
    name: ollama
    base_url: "http://ollama:11434"
    model: llama3.2

  stt:
    name: whisper-native
    model: /models/ggml-base.en.bin
    options:
      language: en

  tts:
    name: coqui
    base_url: "http://tts:5002"
    model: tts_models/en/ljspeech/vits
    options:
      api_mode: standard
      language: en

  embeddings:
    name: ollama
    base_url: "http://ollama:11434"
    model: nomic-embed-text

  vad:
    name: silero
    options:
      frame_size_ms: 30
      speech_threshold: 0.5
      silence_threshold: 0.35

npcs: []

memory:
  postgres_dsn: postgres://glyphoxa:glyphoxa@postgres:5432/glyphoxa?sslmode=disable
  embedding_dimensions: 768

mcp:
  servers: []
